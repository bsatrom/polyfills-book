[[polyfills_chapter_5]]
== Building Your First Polyfill, Part 3 - Performance, Mobile and Edge-Case Testing

Over the last two chapters, we've built a pretty nice cross-browser polyfill from the ground up, and we've even added a complete testing setup to ensure that your library always works, as expected. So while Chapters 3 and 4 were about making sure that your polyfill works, this chapter is about making sure that it works well. In particular, we're going to discuss optimizing your polyfill for performance, dealing with undetectable scenarios and finally, how to handle quirky edge cases that can reveal themselves from time-to-time.

=== Building for Performance

In Chapter 2, I introduced several principles of "responsible polyfill" development. One of these was "Build with performance in mind." The spirit of this principle is to encourage polyfill developers to go beyond delivering a functional equivalent to a native browser feature via their library, but to ensure that this equivalent is also as fast as it possibly can be. 

This is a high bar, for sure. Your polyfill's performance baseline is the native rendering capabilities of the browser, and while your library won't be able to match the speed of a native feature rendered by the browser, doing so should not be your focus. Rather than worrying about a native performance baseline, you should instead strive to pass the front-end developers' "noticeably slower" test. And it's a simple test, really. If, after including your library in his or her application, the app runs "noticeably slower," you can expect that your polyfill will be dropped on the floor, quickly. That, or the developer will contact you and complain. Remember, polyfills are designed to emulate native browser capabilities, so you should consider it your solemn duty *not* to be noticed by developers. Bottom line, while the "noticeably slower" test itself is both far from scientific and something that varies from developer to developer, there are some strategies you can adopt to decrease the chances that a consuming dev will notice your library:

. Set-up Performance Benchmarks
. Don't Execute Code To Early or Too Often
. Iterate Until You're Happy, and Then Iterate Some More

We'll look at each of these, in turn, in this section.

==== Setting Up Performance Benchmarks

First-things-first, if you want to build for performance, you need to be able to test and asses the performance of your polyfill. You certainly *could* eyeball it and judge your library by how fast it "feels" to you, but I suggest being a bit more scientific, if you can stand it. Specifically, I suggest using http://jsperf.com[JSPerf] to benchmark and test your polyfill, not only at the start, but as you continue to iterate and make changes. JSPerf, which is based on the open-source http://benchmarkjs.com[Benchmark.js] library, is a quick and easy way to set-up tests of your library's features and functionality. Alternatively, you *could* use Benchmark.js directly, or even the https://github.com/shama/grunt-benchmark[grunt-benchmark] Grunt plugin, I find that JSPerf has everything I need to perform performance tests across revisions to my polyfills. Plus, it also has pretty charts, courtesy of http://browserscope.org[Browserscope]. In the next section, I'll walk through setting up a simple JSPerf test to show the delta after a performance tweak to my HTML5 Forms polyfill.

==== Don't Execute Code Too Early or Too Often

The next strategy we can employ to pass the "noticeably slower" test is to make sure that our polyfill doesn't execute any code it doesn't have to. This is especially important if your library is a drop-in or opt-in polyfill that performs it's own feature detection. For instance, our HTML5 Forms Polyfill needs to test for browser support of several input types. In Chapter 3, we perform feature detection as we loop over each input in a form, as shown in <<EX5-1>>

[[EX5-1]]
.Form Support with Feature Detection
====
[source, js]
----
(function($, kendo) {
  var ui = kendo.ui,
    Widget = ui.Widget;

  var typeUpgrades = [
  {
    type: 'color',
    upgrade: function(inputs) {
        inputs.kendoColorPicker({ palette: 'basic' });
    }
  },
  {
    type: 'number',
    upgrade: function(inputs) {
        inputs.kendoNumericTextBox();
    }
  },
  {
    type: 'range',
    upgrade: function(inputs) {
      inputs.kendoSlider({
        showButtons: false,
        tickPlacement: 'none'
      });
    }
  }];

  var Form = Widget.extend({
    init: function(element, options) {
      var form = $(element),
          that = this;
      var i, len;

      // base call to widget initialization
      Widget.fn.init.call(this, element, options);

      function isFormTypeSupported(type) {
          if (that.options.alwaysUseWidgets) {
              return false;
          }

          var input = document.createElement('input');
          input.setAttribute('type', type);
          return input.type !== 'text';
      }

      for (i = 0, len = typeUpgrades.length; i < len; i++) {
          var typeObj = typeUpgrades[i];

          if (!isFormTypeSupported(typeObj.type)) { <1>
            var inputs = form.find('input[type=' + typeObj.type + ']');
            typeObj.upgrade(inputs);
          }
      }
    },
    options: {
      // the name is what it will appear in the kendo namespace (kendo.ui.Form).
      // The jQuery plugin would be jQuery.fn.kendoForm.
      name: 'Form',
      alwaysUseWidgets: false
    }
  });

  ui.plugin(Form);
} (jQuery, kendo));
----
<1> Test each feature before "upgrading"
====

===== The First Perf Tweak: Caching Feature Tests

This approach works, but perhaps you noticed that we perform the feature detection test--creating an in-memory input element and setting it's type--each and every time. So, if I have twenty inputs on my form with the new "color" type, I'll perform this dance twenty times. This is unnecessary. The user's browser won't change in the middle of the page load, so there's really no reason for me to perform these feature tests each time through. Instead, it makes more sense to test each feature when my library loads, and cache the result of each test as a boolean that I can access later. <<EX5-2>> shows an example of this for my HTML5 Forms polyfill.

[[EX5-2]]
.Caching Feature Tests at First-Run
====
[source, js]
----
(function($, kendo) {
  var ui = kendo.ui,
    Widget = ui.Widget;

  var typeUpgrades = [
  {
    type: 'color',
    upgrade: function(inputs) {
        inputs.kendoColorPicker({ palette: 'basic' });
    }
  },
  {
    type: 'number',
    upgrade: function(inputs) {
        inputs.kendoNumericTextBox();
    }
  },
  {
    type: 'range',
    upgrade: function(inputs) {
      inputs.kendoSlider({
        showButtons: false,
        tickPlacement: 'none'
      });
    }
  }];

  function isFormTypeSupported(type) {
    var input = document.createElement('input');
    input.setAttribute('type', type);
    return input.type !== 'text';
  }

  var featureDetects = { <1> 
    color: isFormTypeSupported('color'),
    number: isFormTypeSupported('number'),
    range: isFormTypeSupported('range')
  };

  var Form = Widget.extend({
    init: function(element, options) {
      var form = $(element),
          that = this;
      var i, len;

      // base call to widget initialization
      Widget.fn.init.call(this, element, options);

      for (i = 0, len = typeUpgrades.length; i < len; i++) {
          var typeObj = typeUpgrades[i];

          if (!featureDetects[typeObj.type]) { <2>
            var inputs = form.find('input[type=' + typeObj.type + ']');
            typeObj.upgrade(inputs);
          }
      }
    },
    options: {
      // the name is what it will appear in the kendo namespace (kendo.ui.Form).
      // The jQuery plugin would be jQuery.fn.kendoForm.
      name: 'Form',
      alwaysUseWidgets: false
    }
  });

  ui.plugin(Form);
} (jQuery, kendo));
----
<1> Test and cache each feature during the script load
<2> Access the cached test value during the "upgrade" process
====

In <<EX5-2>>, I moved the +isFormTypeSupported+ function outside of my widget initialization code, and created a local +featureDetects+ object to hold the cached, boolean values for each test. Finally, in my main initialization loop, I can access those cached values, and bypass repeated code paths. 

This is nice in theory, and it certainly looks a bit cleaner, but just how fast is it? To answer that question, we can head over to http://jsperf.com[JSPerf] and create a test. 

JSPerf can seem a bit daunting if you've only every viewed others' tests before, but it's actually quite simple to create tests of your own. The basic idea behind JSPerf is to create multiple test cases that execute blocks of JavaScript code--performing operations, mutating the DOM, etc.--that the tool then executes over and over again in order to determine which operations and fastest and slowest. JSPerf takes care of all of the looping and re-runs, and all you need to do is specify the test cases, and any set-up or teardown that should happen during testing.

In order to test just how much feature test caching improves the performance of our code, I created the test shown in <<EX5-3>>. You can also http://jsperf.com/feature-test-cache[access the test online], and run it yourself, if you so desire.

[[EX5-3]]
.JSPerf Test for Feature Test Caching
image::images/ch5-ex3.png[]

The "Preparation Code" section in <<EX5-3>> shows the setup and teardown code that will run before each test, and which does not impact the timing of the tests. Here, I create a global feature test method, +isFormTypeSupported+, as well as a global +featureDetects+ object, similar to <<EX5-2>>. 

The "Test Runner" section contains my actual tests. The "Test Each Time" block does exactly what it says, each time that block is called, it will call the +isTypeSupported+ method. This block mimics my original functionality in <<EX5-1>>. The "Cache Tests" block, on the other hand, simply accesses the cached feature test values. If I run these tests a few times, I'll get a result similar to <<EX5-4>>.

[[EX5-4]]
.JSPerf Test Results for Feature Test Caching
image::images/ch5-ex4.png[]

As you can see from the image above, caching my feature tests is not only faster, it's nearly 60 times faster than performing feature tests each time! Of course, it's important to note that, since JSPerf runs each test case several dozen times over, reported numbers aren't indicative of raw, overall performance gains in my library. Rather, JSPerf is most valuable as a measure of relative performance between options. The bottom line, in this case, is that we know that caching feature tests is faster and, thus, an excellent refactoring choice for my library.

So far, in this section, we've avoided executing unnecessary code by ensuring that feature detection tests only run once when my library is loaded. This is a specific example of a general case and beyond changes like this, another optimization I can perform is to ensure that my library doesn't perform any unnecessary initialization or set-up. Any features or functionality that my library might not need for all browsers should remain dormant until it's needed. Obviously, stylesheets and JavaScript will need to be parsed when they are included, but I want try to execute as little of that code as possible, until my library is called upon. In the case of my library, the only code that runs before I initialize a Form widget is my feature tests, which I've deemed necessary to run up-front since the performance gains are pretty big.

==== Iterate Until You're Happy, Then Iterate Some More

===== The Second Perf Tweak: Caching DOM Elements

- make the change
- add a scenario to jsPerf
- show the performance gain

==== The Third Perf Tweak: Running Feature Detects only once

- make the change
- add a scenario to jsPerf
- show the performance gain

==== The Fourth Perf Tweak: Critical Ordering of Arguments

- make the change
- add a scenario to jsPerf
- show the performance gain

==== The Final Result

- show how our improvements compare to native performance

=== Detecting the Undetectables
- Modernizr's canonical https://github.com/Modernizr/Modernizr/wiki/Undetectables[Undetectables list].
- Strategies for dealing with undetectable cases

==== Undetectable Cases for HTML5 Forms

- For Forms, we can't detect the webforms UI, only constraint validation.
- Date/time input types contain some quirks (http://caniuse.com/#search=datetime)
	- Safari contains date-formatted text fields, but no calendar widget (still reports as text)

==== Dealing with Forms in Mobile Browsers

- Maybe talk mobile here, how I don't want to upgrade fields in iOS or Android 4 and how to deal with that?
- UA sniffing of mobile browsers

=== Dealing with Browser-Specific Edge-Cases

- Talk about things that pop up when we start doing lots of cross-browser testing (esp in IE)
- IE-specific errors for testing input types (cannot set IE)