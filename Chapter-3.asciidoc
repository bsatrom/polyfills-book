[[polyfills_chapter_3]]
== Building Your First Polyfill, Part 1 - Project Setup and Testing

Over the first two chapters of this book, we established a solid foundation for polyfill development, first in Chapter 1 with a discussion of the continued importance of polyfilling to the web platform. In Chapter 2, I shared some essential principles to keep in mind when building "responsible polyfills." These were important chapters to start with, but I'll bet your about ready to get hands on. I know I am. With that in mind, let's turn our attention to the construction of a real world cross-browser polyfill: an HTML5 Forms polyfill. 

Over the next two chapters, I'll take a deep-dive look at the creation of an actual polyfill. In this chapter, we'll look at some good practices for setting up your project, and how to configure your dev environment for automated cross-browser testing.

=== The HTML5 Forms Polyfill

When I first set out to write this book, I considered a lot of different options for a guinea pig polyfill to use. I wanted to target something that was reasonably complex, but straightforward enough to introduce in bits and pieces via text. I also wanted to choose a technology that's implementation status across browsers was more than just "supported in everything but IE." And even though IE will factor into some of the hairier aspects of our polyfill development, I wanted to walk through an example with quirks in as many browsers as possible. For those purposes, there's no better technology to attempt to polyfill than "HTML5 Forms."

What we know of today as "http://www.w3.org/TR/2011/WD-html5-20110525/forms.html[HTML5 forms]" was actually the first technology to be proposed under the umbrella of what we refer to as "HTML5." First introduced outside of the WC3 as "Web Forms 2.0" by a consortium of browser vendors that included Google, Mozilla, Opera Software and Apple, this proposal arrived at a time when the W3C was still pouring much of their effort into the now-deduct XHTML 2.0. As an outflow of "Web Forms 2.0," these vendors formed the Web Hypertext Application Technology Working Group (WHATWG), a sibling standards body to the W3C that still exists today. 

And while it's outside of the scope of this book to discuss the politics of HTML5, various collected standards and competing standards bodies, it is important to note that HTML5 forms has not only been around a while, but it's still one of the most hotly-debated aspects of the HTML5 spec. Certain aspects of the forms spec have near universal support (i.e. forms validation), some of the more visual aspects of the spec--new input types like number, color and datetime--have yet to be consistently implemented across all browsers. What's more, in some cases for those browsers that do support certain types, the specifics of said support are often inconsistent from one implementation to the next, meaning that you, the developer, might not get exactly the behavior you expect, every time.

HTML5 Forms is a minefield. What better area to venture into as a polyfill developer, then, no? It's a bit hairy for sure, but this area of the spec if sufficiently complex enough to expose many of the polyfilling practices that I introduced in the last chapter. 

=== Setting up Your Polyfill project

When starting work on a cross-browser polyfill, we want to begin with the end in mind. That is, before we write a single line of code, we should think about how we plan to distribute our hard work, and how we expect other developers to leverage our polyfill in their apps, and even how we can enable others to contribute to our project. All of these considerations can be addressed at the start of a project with a solid development workflow, which includes several core pieces:

. Source control and collaboration
. Package and dependency management
. Build and Workflow Management
. Automated and Cross-Browser Testing
. Continuous Integration

==== Source control and collaboration

The first step is to think about how and where you'll want to host your code so that a) you've got a backup and full project history in case things go wrong and b) other developers can find, leverage and contribute to your project. For the first part, you'll want to choose a source control solution that's open-source and widely-used. Two examples are http://git-scm.com[Git] and http://mercurial.selenic.com/[Mercurial]. These two systems have a similar command-line syntax for working with files and code repositories, so some developers are comfortable working with either. That said, Git is far and away the most popular source control system in use today, so you'll reach a larger body of potential collaborators by choosing that system.

When paired with a solid code-sharing site, your source control solution also gives you a platform for making your polyfill available to the world. Not only can you store your polyfill source and history in these sites, but you can make that source and history available for others, which is hopefully your goal as a polyfill developer. Just as Git is the most popular source control option around today, http://github.com[GitHub] is the most popular option for hosting and collaborating on all manner of git-based open-source software projects. Other options worth considering, if GitHub is not your cup of tea are http://www.bitbucket.com[BitBucket]--which allows you to host both Git and Mercurial projects--and Microsoft's http://www.codeplex.com/[CodePlex]--which supports Mercurial projects only. For the examples in this book, I've chosen Git as my source control solution and GitHub for code sharing and distribution.

==== Package and Dependency Management

Once you've chosen a source control solution, you'll want to think about how to manage dependencies. By dependencies, I'm not referring to "this polyfill depends on jQuery," but, rather, the 3rd party libraries that your polyfill depends on for things like static analysis, minification, testing and more. We'll talk about those specific tools in a bit, but before you start using these, you need to think about how you plan to include them in your project, and how to declare those dependencies for others who download your work. In the world of JavaScript development, there's no better general-purpose package manager than http://npmjs.org[npm], the Node.js Package Manager. If you have http://nodejs.org[Node.js] installed, you already have npm. If not, head over to http://nodejs.org and grab the appropriate installer for your OS. You'll be using Node and npm heavily throughout your polyfill project and these tools are also a prerequisite for the next few items on our list.

==== Build and Workflow Management

Developing open-source software, including polyfills, is about more than just throwing together a quick sample, some basic tests and a source file. Sure, it's possible to put something online that consists of only these things, I've even done it myself before. Five years ago, it was even a common practice among the front-end community. But as our community has matured, our tools and our processes have evolved, as well. One could make the argument that our tools have matured us, but that's neither here nor there. 

As a front-end developer, I have a workflow that's shared by many others. I write tests. I write code until those tests pass. I repeat. I test across browsers. I write some more code. During development, I keep my source files small and separate, but I want the code I distribute to be in a single file, minified and ready to use in production environments.

Executing all of these tasks--from testing to minification--by hand is a pain. Thankfully, there are great build and workflow tools out there for front-end devs. These tools, which you integrate into your project, can quickly perform these tasks on your behalf, either at your command, or when a change to a project file is observed.

Once such tool is http://gruntjs.com/[Grunt], a simple JavaScript task runner created by Ben Alman. Grunt is a bit of a youngster in the build system world, but it's caught fire among front-end developers and, with lots of community participation, has managed to achieve a good deal of stability in a short time.

I use grunt in my projects , and will do so in this book as well. The tool can be installed via npm (+npm install -g grunt-cli+). For more information, see the online http://gruntjs.com/getting-started[getting started guide]. We'll walkthrough configuring an initial grunt setup in a moment.  

==== Automated and Cross-Browser Testing

If you're building a front-end library, testing is important, and it's vitally important if you building a shim or polyfill! Almost every programming language out there has one or more options for unit testing, and JavaScript is no different. Unit testing, that is, the act of writing and executing code that exercises program code and performs assertions to verify that the program functioned as expected, has become quite popular over the last decade, especially in Agile, eXtreme Programming and Lean Software circles. Not only does unit testing aid the developer in properly shaping the API and behavior of his or her library by writing code (via tests) in the mindset of the consumer, but a suite of tests, over time, serve as a wonderful safety net. With this net in place a developer is free to refactor, rework and otherwise enhance her library, and remain confident in the fact that her tests will catch any regressions that fall through the cracks.

In the world of JavaScript development, there are countless unit testing libraries. I prefer http://pivotal.github.io/jasmine/[Jasmine] a "BDD-style" unit testing library. Other popular options include http://qunitjs.com[QUnit], which is maintained by the jQuery team, and https://github.com/caolan/nodeunit/[NodeUnit].

Unit testing is a great foundation, but we also need to consider cross-browser testing for this project. It is a cross-browser polyfill, after all. As such, our project will also need to include an automated tool that can launch multiple browsers and load our unit tests up in each, thereby ensuring at least basic test coverage across browsers. The tool that I prefer to use for such a task is http://karma-runner.github.io/0.10/index.html[Karma], which you can also install via NPM. There's a bit of setup involved in getting Karma up and running the way I like, but we'll cover that below.

=== Continuous Integration  

The last tool you need to consider for your initial project setup is a remote CI server. This step is completely optional, so if you want to take my advice on items 1-4 and ignore me on this one, that's ok. That said, the biggest advantage of a remote CI server for an open-source project is, in my mind, the ability to run basic project setup and unit tests in a clean environment. Doing so ensures that you properly declare dependencies via npm and that you never check-in code that fails one or more tests and just walk away. In my mind, it's better to get the news that you did something wrong from a CI server than from a human struggling to run the latest bits from your project.

For my projects, I prefer to use https://travis-ci.org/[Travis], a CI server used by many in the open-source community. It's easy to set-up and configure, and you can even place status badges on your project's home page signifying it's current pass/fail status on the server. Another, newer option that I've recently discovered is http://wercker.com/[Wercker]. I'll be using Travis for this book, but Wercker is certainly worth checking out for your next project, open source or otherwise.

=== Initial Project Structure

Once we've made all of the appropriate tool choices, from source control to your build system, we're ready to create our project! For the rest of the book I'll be using the tools I indicated in each section above, so if you're choosing otherwise and following along, you might need to adjust things here and there to get the same result.

First things first, make sure you have all of the tools I mentioned above installed on your development machine. Then, create an empty directory for your polyfill and open a terminal or console window in that new directory. Next, we'll initialize a new GitHub repo by running the +git init+ command.

Once you've initialized your local git repository, you'll want to connect it to the remote repository that will be hosting your project online, which you can do by running a command similar to  <<EX3-1>>.

[[EX3-1]]
.Setting up a new Git remote
====
[source, shell]
----
git remote add git@github.com:bsatrom/html5-forms-polyfill.git
----
====

Now, your local and remote repositories are all set-up and it's time to add some essential project files. Here's the basic project structure I recommend for most open-source polyfills (assuming a view from the folder root):

- +dist/+ - The minified and concatenated files you plan to distribute; i.e. the "binaries" for your polyfill
- +lib/+ - Any 3rd-party libraries that your Polyfill depends on (jQuery, Underscore, etc.)
- +sample/+ - The sample project for the polyfill
- +spec/+ - Home for your unit tests
- +src/[js,css]+ - Source JavaScript and CSS files
- +.gitignore+ - A list of files for Git to ignore when found in your project. GitHub can create one of these files for you when creating a new project. If you go that route, select the "Node" template.
- +CHANGELOG.md+ - A laundry-list of minor and breaking changes for each version of your project. 
- +CONTRIBUTING.md+ - Essential if you plan to accept contributions for your project. 
- +README.md+ - the readme for your project. GitHub automatically treats this file as the main entry point when anyone visits your project. It should describe the purpose and goals of the polyfill--as I discussed in Chapter 1--features of the project, a roadmap for the projects, installation and usage instructions and anything else you think might be useful to consumers of or collaborators on your polyfill.
- +LICENSE.md+ - Every open-source project needs a license. Which license you choose is up to you, but permissive licenses, such as MIT and Apache 2.0 will garner more interest and, possibly, participation from other developers. GitHub can also generate this file for you, based on the license chosen at project creation. 

[NOTE]
====
The advice of a no-talent hack, such as yours truly, should not be confused for legal expertise. As such, your best bet is to consult with a legal expert before choosing an open source license. You can also visit the great http://choosealicense.com/[ChooseALicense.com] for more information about the dizzying array of open-source licenses available. But still, you should talk to a lawyer if you want an expert legal perspective in your choice of license. 
====

With your basic project structure in place, your next steps are to configure +npm+ and +grunt+. First, I'll run +npm init+ inside my project directory and follow the interactive prompts. You can see the result of running the command in my terminal in <<EX3-2>>. Once you're done, npm will create a +package.json+ file that looks similar to <<EX3-3>>. While this file isn't strictly required unless you plan to publish your polyfill to npm, it will make it easier to work with Grunt, which we'll set up next. 

[[EX3-2]]
.Running +npm init+ to configure your package.json file
image::images/ch3-ex3.png[]

[[EX3-3]]
.Sample package.json file
====
[source, js]
----
{
  "name": "html5-forms-polyfill",
  "version": "0.0.1",
  "description": "A cross-browser polyfill for HTML5 forms features",
  "repository": {
    "type": "git",
    "url": "git://github.com/bsatrom/html5-forms-polyfill.git"
  },
  "keywords": [
    "html5",
    "polyfill",
    "forms",
    "validation"
  ],
  "author": "Brandon Satrom",
  "license": "MIT",
  "readmeFilename": "README.md",
  "gitHead": "4a2f3578443f539d52c645563fe47824bf4fb377"
}
----
====

Next, let's install Grunt. Before you run the Grunt config step, you'll need to add the following to your package.json and run +npm install+ from the terminal, which will make sure that the Grunt command-line interface is available in your project.

[[EX3-4]]
.Grunt dependencies in package.json
====
[source, js]
----
"devDependencies": {
  "grunt": "~0.4.1",
  "grunt-contrib-jshint": "~0.6.0",
  "grunt-contrib-uglify": "~0.2.2"
  "grunt-contrib-concat": "~0.3.0",
  "grunt-contrib-cssmin": "~0.6.1"
}
----
====

Configuring grunt at this point is a bit more manual. While there are http://gruntjs.com/project-scaffolding[several +grunt-init+ tasks] available for you to use, since our project is a bit specific, it's easier if we just start with a very basic gruntfile, as shown in <<EX3-5>>. Create a new file at the project root called +gruntfile.js+ and copy the contents below into that new file.

[[EX3-5]]
.Starter gruntfile.js for our Polyfill
====
[source, js]
----
module.exports = function(grunt) {
  // Project configuration.
  grunt.initConfig({
    pkg: grunt.file.readJSON('package.json'),
    concat: {
      options: {
        separator: ';',
        banner: '// kendo-ui-forms v<%= pkg.version %>'
      },
      dist: {
        src: [ 'src/js/*.js' ],
        dest: 'dist/js/kendo.forms.js'
      }
    },
    uglify: {
      options: {
        banner: '// kendo-ui-forms v<%= pkg.version %>'
      },
      dist: {
        files: {
          'dist/js/kendo.forms.min.js': '<%= concat.dist.dest %>'
        }
      }
    },
    cssmin: {
      options: {
        banner: '// kendo-ui-forms v<%= pkg.version %>'
      },
      combine: {
        files: {
          'dist/css/kendo.forms.css': 'src/css/*.css'
        }
      },
      minify: {
        expand: true,
        cwd: 'src/css/',
        src: ['*.css', '!*.min.css'],
        dest: 'dist/css/',
        ext: '.forms.min.css'
      }
    },
    jshint: {
      files: ['gruntfile.js', 'src/**/*.js', 'spec/js/*.js'],
      options: {
        globals: {
          jQuery: true,
          console: true,
          module: true,
          document: true
        }
      }
    }
  });

  // Plugins for other grunt tasks.
  grunt.loadNpmTasks('grunt-contrib-uglify');
  grunt.loadNpmTasks('grunt-contrib-jshint');
  grunt.loadNpmTasks('grunt-contrib-concat');
  grunt.loadNpmTasks('grunt-contrib-cssmin');
  
  // Default task(s).
  grunt.registerTask('default', ['jshint']);
  grunt.registerTask('minify', ['jshint', 'concat', 'cssmin', 'uglify']);
};
----
====

Though it seems like there's a lot going on here, a grunt file is pretty easy to parse once you get the hang of it. A gruntfile is made up of a series of named tasks, like +concat+, +uglify+ and the like. Each task tells grunt what actions to perform, and which files to perform those actions on when that task is executed. In this starter gruntfile, I've defined four tasks.

. +concat+ - Combines all of the JavaScript files in the +src/+ directory into a single file.
. +uglify+ - Minifies the concatenated JavaScript file
. +cssmin+ - Combines and minifies any CSS files defined in +src/+.
. +jshint+ - Performs static analysis on my JavaScript source files to make sure I'm following a consistent coding style. (see http://jshint.com for more information)

At the bottom of my +gruntfile+, I've also defined two additional tasks: a +default+ task, which runs when I execute the +grunt+ command with no other task, and a custom +minify+ command, which is a combination of several commands defined above.

Once your gruntfile is complete and the options match your project, run +grunt+ from the terminal. If your gruntfile checks out, you'll get a "Done, without errors" message, which means we can continue on! If not, grunt will point you in the direction of the problem, which is usual a minor syntax issue. Now, let's get some unit tests set up!

=== Configuring Unit Tests with Jasmine

Testing is critical for a good, "responsible" polyfill, and I recommend that your own project be covered by at least a good set of unit tests. Testing frameworks like Jasmine and qUnit are easy to set up and configure and, once you get going with them, you'll be glad that you have a full suite of tests backing up your polyfill development.

To start using Jasmine for my unit tests, I'll create a +lib+ directory inside of my +spec+ directory and place the jasmine bits inside. I'm also going to include the https://github.com/velesin/jasmine-jquery[jasmine-jquery] library, which I'll need in order to automatically execute my tests via grunt. 

Next, I'll create a +runner.html+ file at the root of the +spec+ folder, and I'll populate it with the contents of [[EX3-6]]. Many JavaScript frameworks, Jasmine included, use an html file as their "test runner" by loading up dependencies, the project source and then executing those tests against DOM interactions on the page. On this page, we'll specify all of the CSS and JavaScript dependencies for our polyfill, including jQuery and Kendo UI for widgets and framework features, and then load up our tests via +fixtures.js+. 

[[EX3-6]]
.Jasmine runner.html file
====
[source, html]
----
<!DOCTYPE html>
<html>
  <head>
    <title>Kendo UI Forms Test Runner (Jasmine)</title>
    <meta charset="UTF-8">
    <!-- Styles -->
    <link rel="shortcut icon" type="image/png" href="lib/jasmine-1.3.1/jasmine_favicon.png">
    <link rel="stylesheet" type="text/css" href="lib/jasmine-1.3.1/jasmine.css">
    <link rel="stylesheet" href="../lib/css/kendo.common.min.css" />
    <link rel="stylesheet" href="../lib/css/kendo.default.min.css" /> <1>
    
    <!-- Jasmine and Jasmine-jQuery -->
    <script type="text/javascript" src="lib/jasmine-1.3.1/jasmine.js"></script>
    <script type="text/javascript" src="lib/jasmine-1.3.1/jasmine-html.js"></script>
    <script src="../lib/js/jquery.min.js"></script>
    <script type="text/javascript" src="lib/jasmine-jquery.js"></script>
        
    <!-- Kendo UI -->
    <script src="../lib/js/kendo.web.min.js"></script> <2>
    <script src="../src/js/kendo.forms.js"></script> <3>
    
    <!-- Specs -->
    <script src="js/fixtures.js"></script> <4>
  </head>
  <body>
    <!-- Jasmine -->
    <script type="text/javascript">
      (function() {
        var jasmineEnv = jasmine.getEnv();
        jasmineEnv.updateInterval = 1000;

        var htmlReporter = new jasmine.HtmlReporter();

        jasmineEnv.addReporter(htmlReporter);

        jasmineEnv.specFilter = function(spec) {
          return htmlReporter.specFilter(spec);
        };

        var currentWindowOnload = window.onload;

        window.onload = function() {
          if (currentWindowOnload) {
            currentWindowOnload();
          }
          execJasmine();
        };

        function execJasmine() {
          jasmineEnv.execute();
        }

      })();
    </script>
  </body>
</html>
----
<1> These two lines include the Kendo UI CSS Styles
<2> The main source file for Kendo UI Web, which our polyfill needs for UI widgets and framework features
<3> This is the main source file for our polyfill
<4> This file contains all of the script-based tests
====  

With the runner done, let's create the key file for our testing, +fixtures.js+. [[EX3-7]] contains an initial test file with a couple of tests. You'll notice that Jasmine uses functions like +describe+, +it+ and +expect+, and that my test names are written in narrative form. Because Jasmine is a BDD-style testing framework, you'll hopefully find, as I do, that it's easy to write readable test names and assertions that make sense, not just now, but when you're hunting down regressions later. 

<<EX3-7>>
.Basic Jasmine fixtures file for our polyfill
====
[source, js]
----
describe('Kendo Forms Widget Test Suite', function() {
  
  describe('Form initialization tests', function() {
		
    describe('Form Widget initialization', function() {
      
      it('should exist in the kendo.ui namespace', function() {
        expect(kendo.ui.Form).toBeDefined();
      });

      it('should be able to perform imperative initialization with JavaScript', function() {
        expect($('#imperative-form').kendoForm).toBeDefined();
      });

    });
  });
});
----
====

With this setup done, let's go ahead and run these tests in the browser. If Jasmine is properly configured, you should see two failing tests, as we do [[EX3-8]]. So we have successfully configured our testing framework. Now, let's go make these tests pass!

[[EX3-8]]
.Jasmine running in the browser
image::images/ch3-ex9.png[]

=== Red to Green: Making the First Tests Pass

When I start a new project, or add unit tests to an existing project, I like to start small and try to get a few quick win tests under my belt. This is partly because I'm still feeling out functionality in the early stages of a project, but also because I want to see my test suite running and passing as quickly as possible. It's far easier to suss out problems with my test suite setup with a smaller number of tests.

With that in mind, the first two failing specs we've added to my project are minor, and easy to fix, but they help lay the foundation for my polyfill. As discussed previously, my HTML5 Forms polyfill will be built on top of http://www.kendoui.com[Kendo UI], a library from http://www.telerik.com[Telerik] that provides all of the UI widgets and forms framework features I need. As a result, all I need to do with my polyfill is to wire up the automated intelligence that knows how to perform an "HTML5 form" into a smart form that uses Kendo UI widgets and validation features when the browser doesn't support these.

Kendo UI itself exposes it's UI widgets to developers in two ways. Developers can either initialize Kendo UI Widgets using a jQuery plugin-style syntax, or by using declarative +data-+ style widget initialization. When building extension widgets to Kendo UI, which is something I've chosen to do with my polyfill, I need to follow the same pattern, so users of my library will be able to interact with my polyfill just as they would with a Kendo UI Autocomplete or DateTimePicker widget. As such, I'll need to support the initialization styles depicted in <<EX3-9>> and <<EX3-10>>.

[[EX3-9]]
.Initializing the Forms polyfill via JavaScript
====
[source, html]
----
<form id="myForm">
  <!-- Rest of form declaration -->
</form>
<script>
  $('#myForm').kendoForm();
</script>
----
====

[[EX3-10]]
.Initializing the Forms polyfill via declarative initialization
====
[source, html]
----
<form action="input.html" data-role="form">
  <!-- Rest of form declaration -->
</form>
<script>
  kendo.init(document.body);
</script>
----
====

The tests in [[EX3-7]] are looking for key pieces of information. First, we check to make sure that our polyfill exists as a widget in the Kendo UI namespace, as +kendo.ui.Form+. Next, we want to ensure that the polyfill widget is available as a jQuery plugin, as illustrated in <<EX3-9>>. To make those tests pass, we can create the initial skeleton of our polyfill in a new file (in +src/+) called +kendo.forms.js+ and add the code in <<EX3-11>>

[[EX3-11]]
.Creating the core widget definition for our Kendo UI Forms polyfill
====
[source, js]
----
(function($, kendo) {
  var ui = kendo.ui,
    Widget = ui.Widget,
    formWidget;

  var Form = Widget.extend({
    init: function(element, options) {
      // base call to widget initialization
      Widget.fn.init.call(this, element, options);
    },
    options: {
      // the name is what it will appear in the kendo namespace (kendo.ui.Form).
      // The jQuery plugin would be jQuery.fn.kendoForm.
      name: 'Form'
    }
  });

  ui.plugin(Form);
} (jQuery, kendo));
----
====

The contents of <<EX3-11>> represent the standard way of creating extended Kendo UI widgets. First, we create a new +Form+ widget by extending the +kendo.ui.Widget+ base type. The name "Form," which I set in the options configuration value is ultimately what's exposed publicly, and is what my two tests are looking for. Finally, I'll "enable" my new polyfill by adding the Form variable to Kendo UI's widget collection via the +kendo.ui.plugin()+ method.

There's a lot more I'll need to add inside of +kendo.forms.js+ before I have a functional polyfill, but the code we've written do far lays the foundation for my library, and it's also enough to make my first tests pass, as you can see in <<EX3-12>>.

[[EX3-12]]
.Jasmine running in the browser
image::images/ch3-ex13.png[]

=== Running Jasmine Tests via Grunt

So far, we've gotten Jasmine configured for our unit tests, and we've even gotten a couple of failing tests to pass. This is a great start, but all of our work is in the browser, and running our tests requires that we refresh a browser tab to verify. This is probably fine for many projects, but I'd like to be able to execute my tests in both the browser and via the command-line, which will come in handy when I start working with Karma and Travis CI, later.

Thankfully, I'm not alone in my desire for console-based JavaScript testing, and there just so happens to be a Grunt plugin for Jasmine that I can add to my project. First, I'll want to configure jasmine by adding a few lines to my +gruntfile+. I'll add the +grunt-contrib-jasmine+ task declaration to the bottom of the file, like so +grunt.loadNpmTasks('grunt-contrib-jasmine');+. Then, I need to add a jasmine task to the +initConfig+ section of the file, as shown in <<EX3-13>>. This task definition tells Jasmine where to look to find my project source, the specs to run and finally, any 3rd party "vendor" libraries that should also be loaded.

[[EX3-13]]
.Adding a jasmine grunt task
====
[source, js]
----
jasmine: {
  src: ['lib/**/*.js', 'dist/js/kendo.forms.min.js'],
  options: {
    specs: 'spec/js/*.js',
    vendor: [
      'spec/lib/jasmine-jquery.js'
    ]
  }
}
----
====

Next, I'll want to install the jasmine grunt plugin via the terminal command +npm install grunt-contrib-jasmine --save-dev+.  Once I've done so, I can run the command +grunt jasmine+ via the console, and I'll get a result that looks like <<EX3-14>>.

[NOTE]
====
The +save-dev+ switch will automatically save the package as a +devDependency+ in your package.json file, ensuring that other devs, and your CI environment can quickly replicate your setup. 
====

[[EX3-14]]
.Running jasmine via the console
====
[source, shell]
----
$ grunt jasmine
Running "jasmine:src" (jasmine) task
Testing jasmine specs via phantom
..
2 specs in 0.001s.
>> 0 failures

Done, without errors.
----
====

Now I've got Jasmine running in the browser, and in the terminal, which is nice! Unfortunately, our configuration work isn't quite done yet. Everything works great so far because neither of our initial tests access the DOM. However, once we need to access the DOM, things get a bit tricky, so I'll need to add a little more configuration to keep this happy testing party going.

Let's add our third test, and the first to access the DOM. I'll open +fixtures.js+ back up and add the following test:

[[EX3-15]]
.Testing declarative form initialization
====
[source, js]
----
it('should be able to perform declarative initialization with data attributes', function() {
  kendo.init(document.body);

  expect($('#declarative-form').data('kendoForm')).not.toBe(null);
});
----
====

As I mentioned above, Kendo UI widgets can be declared one of two ways, either using JavaScript, or via +data-role+ declaration and calling +kendo.init+ on a container, which creates widgets for every element inside of that container. The test above calls +kendo.init+ on +document.body+ which will look for every element with a +data-role+ attribute, and initialize that element, accordingly.

When I first add this test, it will fail, but I can make it pass by adding the following to the +runner.html+ file, just inside the +<body>+ element:

[[EX3-16]]
.Declarative initialization of a Form widget
====
[source, html]
----
<form id="declarative-form" data-role="form"></form>
----
====

Now, if I rerun my Jasmine tests in the browser, all three will pass. That's nice, but in the spirit of keeping our test options option, let's rerun the +grunt jasmine+ command and see what happens. Spoiler alert: it looks like [[EX3-17]]. That's a failing test. Why did our test fail in my terminal, even though it worked in the browser? The answer lies in the DOM, or lack thereof, that is. When I'm using Jasmine via the console, there is no DOM available for my tests, so in order to leverage the DOM for testing, I need to do a bit of additional set-up. For that, I'll use the https://github.com/velesin/jasmine-jquery[jasmine-jquery] library, which allows me to load HTML files into my specs and execute my tests against them.

[[EX3-17]]
.Running Jasmine DOM tests in the console
image::images/ch3-ex18.png[]

First, I'll need to move the form tag from <<EX3-17>> into a standalone HTML file, and I'll place that file in a +spec/javascripts/fixtures/+ directory--the location is a convention jasmine-jquery uses. Then, I need to add the jasmine-jquery fixture loader to my +fixtures.js+ file, so I'll add the following to line 4:

[[EX3-18]]
====
[source, js]
----
var fixtures = jasmine.getFixtures();
if (document.location.pathname.indexOf('runner.html') > 0) {
  // We're running jasmine in the browser
  fixtures.fixturesPath = '../spec/javascripts/fixtures';
}
----
====

In order to run jasmine in multiple environments, I do have to add a bit of path manipulation, as you can see in the sample above. If I'm running my tests in the console, the default path (spec/javascripts/fixtures) works for loading fixtures. If I'm in the browser, however, I need to adjust things a little. Finally, in my latest test, <<EX3-15>>, I'll add a call to jasmine-jquery's +load+ method to load up my HTML fixture. The complete test is listed in <<EX3-19>>.

[[EX3-19]]
====
[source, js]
----
it('should be able to perform declarative initialization with data attributes', function() {
  fixtures.load('declarative-form.html');

  kendo.init(document.body);

  expect($('#declarative-form').data('kendoForm')).not.toBe(null);
});
----
====

When I re-run +grunt jasmine+ in the console, I should see all green. I can also re-run the tests in my browser, where everything also passes with flying colors. I now have a complete unit test setup that works in the browser and via the console, which is about to come in quite handy!

=== Configuring Cross-Browser Tests with Karma

Now that we have a good testing setup with Jasmine and Grunt, let's take this party to the next level and add in some cross-browser testing. While automated cross-browser testing might be considered overkill for some types of projects, it's a must when building a polyfill. As you build your polyfill, you'll quickly discover cases where a certain test isn't needed in your everyday development browser because the feature is present, but the feature still needs a good solid test because your polyfill provides capabilities for another browser to leverage. Performing automated testing across several installed browsers can be a quick sanity check to ensure that development of your polyfill is progressing along without a hitch and, thankfully, there are some great tools out there that we can pair with our existing grunt workflow. My tool of choice is Karma, a simple test runner than can call out to all major browsers using test runner plugins.

[NOTE]
====
While automated, cross-browser testing is a great safety net for the polyfill developer, it's no substitute for real, actual testing across browsers, especially those older versions of IE where browser quirks lie in wait. Fear not, however! As I'll share in Chapter 4, there are some great options for performing physical testing of older browsers, even IE 6-8.
====

To get started with Karma, I'll need to install grunt-karma via npm:

[[EX3-20]]
====
[source, shell]
----
npm install grunt-karma --save-dev
----
====

Both Karma and grunt-karma will be installed, and a series of karma-related dependencies will be added to your +package.json+ file. Next, you'll want to add the line +grunt.loadNpmTasks('grunt-karma');+ to the end of the +loadNpmTasks+ calls in your +gruntfile+. Then, I'll add the karma task to my +gruntfile,+ starting with a bit of logic to populate an array of browsers I want to test with, at the top of the file.

[[EX3-21]]
====
[source, js]
----
var browsers;
(function() {
  var os = require('os');
  browsers = ['Chrome', 'Firefox', 'Opera'];
  if (os.type() === 'Darwin') {
    browsers.push('ChromeCanary');
    browsers.push('Safari');
  }
  if (os.type() === 'Windows_NT') {
    browsers.push('IE');
  }
})();
----
====

In this snippet, I'm using Nodejs to interrogate with which OS I'm testing. If I'm using OSX ("Darwin"), I'll add Chrome Canary and Safari. If, on the other hand, I'm on Windows, I'll add IE to my browsers array. Next, I'll add a task for Karma to the +grunt.initConfig+ method:

[[EX3-22]]
====
[source, js]
----
karma: {
  options: {
    configFile: 'conf/karma.conf.js',
    keepalive: true
  },
  forms: {
    browsers: browsers
  }
}
----
====

Key in this section is the +configFile+ property, which accepts a path to a separate Karma configuration file. Karma has a lot of configuration options, so placing these in a separate file is usually a good approach. The contents of my +karma.conf.js+ can be found in <<EX3-23>>.

[[EX3-23]]
====
[source, js]
----
module.exports = function(config) {
  config.set({
    // base path, that will be used to resolve files and exclude
    basePath: '../',

    // list of files / patterns to load in the browser
    files: [
      'lib/js/*.js',
      'dist/js/kendo.forms.min.js',
      {pattern: 'lib/js/jquery.min.js', watched: false, served: true, included: true},
      {pattern: 'spec/lib/jasmine-jquery.js', watched: false, served: true, included: true},
      {pattern: 'src/js/*.js', watched: true, served: true, included: false},
      {pattern: 'spec/**/*.html', included: false},
      'spec/javascripts/*.js',
    ],

    // list of files to exclude
    exclude: [],

    frameworks: ['jasmine'],
    reporters: ['progress'],
    port: 9876,
    runnerPort: 9100,
    colors: true,
    logLevel: config.LOG_INFO,
    autoWatch: true,
		
		browsers: ['ChromeCanary'],
		captureTimeout: 50000,
    singleRun: true,
    reportSlowerThan: 500,
    preprocessors: {},

    plugins: [
      'karma-jasmine',
      'karma-chrome-launcher',
      'karma-firefox-launcher',
      'karma-safari-launcher',
      'karma-opera-launcher',
      'karma-script-launcher'
    ]
  });
};
----
====

By default, Karma includes the launchers for Firefox and Chrome, so I'll need to install the Opera and Safari launchers to use them:

[[EX3-34]]
====
[source, shell]
----
npm install karma-opera-launcher --save-dev
npm install karma-safari-launcher --save-dev
----
====

Once I've installed those two additional launchers, I should be able to run karma using grunt with the +grunt karma+ command. If I do that, I should see all of my browsers launch, but one of my three initial tests will fail. Can you guess which ones? That's right, the DOM tests. Much as I did for Jasmine in the console, I need to add a path condition for Karma to my +fixtures.js+ file, as shown in <<EX3-35>>.

[[EX3-35]]
====
[source, js]
----
if (document.location.pathname === '/context.html') {
  // Karma is running the test, so change the base
  fixtures.fixturesPath = 'base/spec/javascripts/fixtures';
} else if (document.location.pathname.indexOf('runner.html') > 0) {
	// We're running jasmine in the browser
  fixtures.fixturesPath = '../spec/javascripts/fixtures';
}
----
====

With this additional condition, I'm looking for +context.html+ in my path, which is the context under which Karma runs. If that value is found, I'll adjust the base +fixturesPath+ to account for the location from which Karma loads these files. Otherwise, I'll look for my in-browser +runner.html+, as before. And that's it, I can return to the console and run +grunt karma+ and watch all my tests pass in five browsers, as shown in <<EX3-36>>. It's a thing of beauty!

[[EX3-36]]
.Running cross-browser tests with Karma
image::images/ch3-ex37.png[]

=== Automate your Polyfill Testing with Grunt and Travis-CI

Thus far in this chapter, we've set up a new polyfill project, we've configured npm and grunt for our development workflow, and we've added Jasmine and Karma for unit and cross-browser testing. All of these moving pieces work great alone, but we're now going to bring them together for a killer polyfill development workflow. As mentioned earlier, Grunt gives you the ability to create custom tasks that chain together predefined tasks in interesting ways. One example is the +minify+ task in <<EX3-5>> which automatically runs JSHint, concatenates your source files and then runs uglifyJS to minify them. 

Now that we've added some testing, let's add a few more custom tasks that combine our test frameworks with our JSHint and magnification tasks. 

[[EX3-37]]
====
[source, js]
----
grunt.registerTask('test', ['minify', 'jasmine']);
grunt.registerTask('x-test', ['minify', 'jasmine', 'karma:forms']);
----
====

Now, I can run +grunt test+ in the console and have my files linted, minified, combined and tested, or I can run +grunt x-test+, which will do all of the above and then run my tests across all browsers using Karma. And while task customization is nice, what I'd really like to be able to do is execute a grunt command once, and have that command watch my source files for changes. Then, when one of those files is saved, grunt will execute one or more tasks, automatically. Sounds awesome, right? It is, and with grunt, it's built in. All I need is the grunt-contrib-watch plugin, which I can install via npm:

[[EX3-38]]
====
[source, shell]
----
npm install grunt-contrib-watch --save-dev
----
====

Then I'll include the task via a call to +loadNpmTasks+:

[[EX3-39]]
====
[source, js]
----
grunt.loadNpmTasks('grunt-contrib-watch');
----
====

And finally, I'll add the task to +grunt.initConfig+:

[[EX3-40]]
====
[source, js]
----
watch: {
  scripts: {
    files: ['<%= jshint.files %>'],
    tasks: ['test'],
    options: {
      nospawn: true
    }
  }
}
----
====

Now, I can run +grunt watch+ before I begin working on my polyfill. As I make changes to important files, grunt will pick those up, lint the files and run my Jasmine tests, automatically, as shown in <<EX3-41>>.

[[EX3-41]]
.Developing iteratively with +grunt watch+
image::images/ch3-ex42.png[]

Before we wrap up this chapter, there's one final piece of setup I suggest you perform when building a cross-browser polyfill. That is, configuring a CI server to run your tests and provide you with that extra-level sanity check. As I said above, I prefer Travis CI because the service is free for open source projects, and it's dead-simple to configure. In fact, all I need in my project is to add a file called +.travis.yml+ with a few options, as shown in <<EX3-42>>.

[[EX3-42]]
====
[souce, yaml]
----
language: node_js
node_js:
  - "0.10"
  - "0.8"
before_script:
  - npm install -g grunt-cli
----
====

This file, which I'll include in my Git repository and push to GitHub, tells Travis that I'm running a NodeJS app, and that I'd like to test using Node v0.10 and v0.8. I've also included the +before_script+ option to ensure that the CI server has the grunt cli installed, which I need to run my tests. Once I've added this file and pushed it to GitHub, I can head over to the http://travis-ci.org[Travis website] and follow their http://about.travis-ci.org/docs/user/getting-started/[Getting Started] guide to configure my project with their service.

Once everything is set up, any time I push a commit to my repo from GitHub to Travis, the service will spin up and run my tests, giving me that extra measure of defense for my polyfill. <<EX3-43>> shows an example status screen for my HTML5 Forms polyfill. Looks like green!

[[EX3-43]]
.Developing iteratively with +grunt watch+
image::images/ch3-ex44.png[]

=== The Bottom Line: Use What Works for you!

We've covered a TON of ground in this chapter, and while very little of it has been specific to polyfill development, I felt it was an important one to include because a great polyfill needs tests--and lots of 'em--and a rock-solid development workflow. As you'll see in the next chapter, polyfill development can get hairy at times, especially as you delve into oldIE, so the more rock-solid your tests and your workflow, the better off you'll be as you head down the narrow road.

In this chapter, I mentioned a lot of third-party and open source technologies that I prefer to use when building polyfills. Some of these might work for you as well, while in other cases you have a personal favorite you like to use. That's ok! All that matters is that you get a good dev and test workflow in place early on, no matter which tools your choose to use.

Now that our development and testing workflow is in place, let's talk about some of the critical ins and outs of building that cross-browser polyfill of yours.